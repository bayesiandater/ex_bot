{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11434ba9-38fb-419f-a996-c38edb574680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from transformers import GPT2LMHeadModel, GPT2Tokenizer\n",
    "import numpy as np\n",
    "import random\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import Trainer, GPT2Tokenizer, GPT2LMHeadModel, AdamW, get_linear_schedule_with_warmup, TrainingArguments, DataCollatorForLanguageModeling\n",
    "from tqdm import tqdm, trange\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import pickle\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14c4d49c-81ba-479e-91c8-0fe1f1f9b450",
   "metadata": {},
   "outputs": [],
   "source": [
    "msg_from_ex = pickle.load(open(\"/Users/bayesiandater/ex_bot/resources/msg_from_ex\", \"rb\"))\n",
    "msg_from_ex = [m.lower() for m in msg_from_ex if m.strip() != \"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0c76510d-a607-4155-af1a-970c4f5ed48a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = np.random.default_rng(713)\n",
    "train_idx = rng.integers(low=0, high=len(msg_from_ex), size=int(0.8 * len(msg_from_ex)))\n",
    "valid_idx = [i for i in range(len(msg_from_ex)) if i not in train_idx]\n",
    "train_ls, valid_ls = np.array(msg_from_ex)[train_idx], np.array(msg_from_ex)[valid_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0166131f-0133-4fdc-895d-eb0aa1c25108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([54., 27., 24., 14.,  3.,  3.,  0.,  1.,  0.,  1.]),\n",
       " array([ 1. ,  3.1,  5.2,  7.3,  9.4, 11.5, 13.6, 15.7, 17.8, 19.9, 22. ]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist([len(m.strip().split()) for m in train_ls])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba345c31-6f3e-405a-ad12-4f8d327fe21a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the custom tokens to add to tokenizer\n",
    "# get the GPT2 token list\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n",
    "\n",
    "GPT2_tokens = []\n",
    "for w in tokenizer.encoder.keys():\n",
    "    w = w.strip(\"Ä \").lower()\n",
    "    GPT2_tokens.append(w)\n",
    "    \n",
    "# only add all whole words from both train + valid sets \n",
    "# that are not in the original GPT2 tokenizer's vocabulary 15\n",
    "all_words = []\n",
    "for m in msg_from_ex:\n",
    "    m = m.strip(string.punctuation).lower().split()\n",
    "    all_words += m\n",
    "\n",
    "added_tokens = []\n",
    "for word, freq in Counter(all_words).most_common():\n",
    "    if word not in GPT2_tokens:\n",
    "        added_tokens.append(word)\n",
    "        \n",
    "del tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff74678-6805-4bb9-aafd-22e5c3a3844a",
   "metadata": {},
   "outputs": [],
   "source": [
    "added_tokens = [\"coz\", \"noice\", \"lmaooo\", \"ooh\", \"uhh\", \"prolly\", \"yesss\", \"nvm\", \"ooof\", \"thingy\", 'ðŸ‘€',]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e6d1f290-c334-4f43-9dce-db3aa18946b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MSG(Dataset):  \n",
    "    def __init__(self, ls_stc, truncate=False, gpt2_type=\"gpt2\", max_length=1024, added_tokens=None):\n",
    "\n",
    "        self.tokenizer = GPT2Tokenizer.from_pretrained(gpt2_type)\n",
    "        special_tokens = {'pad_token':'<|pad|>','sep_token':'<|sep|>'}\n",
    "        self.tokenizer.add_special_tokens(special_tokens)\n",
    "        if added_tokens is not None:\n",
    "            self.tokenizer.add_tokens(added_tokens)\n",
    "        self.msgs = []\n",
    "        max_len = 0\n",
    "        \n",
    "        for m in ls_stc:\n",
    "            m = torch.tensor(\n",
    "                self.tokenizer.encode(self.tokenizer.bos_token + f\"{m[:max_length]}\" + self.tokenizer.eos_token, \\\n",
    "                                      max_length=15, padding=\"max_length\", truncation=True))\n",
    "            max_len = max(len(m), max_len)\n",
    "\n",
    "            self.msgs.append(m)\n",
    "        \n",
    "        if truncate:\n",
    "            self.msgs = self.msgs[:20000]\n",
    "            \n",
    "        self.msgs_count = len(self.msgs)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.msgs_count\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        return self.msgs[item]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "73c31c17-fae6-4551-ba9d-4537aa5d39f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_custom_train = MSG(train_ls, truncate=True, gpt2_type=\"gpt2\", added_tokens=added_tokens)  \n",
    "ds_custom_valid = MSG(valid_ls, truncate=True, gpt2_type=\"gpt2\", added_tokens=added_tokens)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cee51997-5bc8-468b-8529-cce1d8469259",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_collator = DataCollatorForLanguageModeling(\n",
    "        tokenizer=ds_custom_train.tokenizer,\n",
    "        mlm=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "04405cbf-a0bf-4a0c-946f-cdf8d47188b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = TrainingArguments(\n",
    "    output_dir=\"/Users/bayesiandater/ex_bot\",          # output directory\n",
    "    num_train_epochs=6,              # total # of training epochs\n",
    "    per_device_train_batch_size=10,  # batch size per device during training\n",
    "    per_device_eval_batch_size=10,   # batch size for evaluation\n",
    "    warmup_steps=200,                # number of warmup steps for learning rate scheduler\n",
    "    weight_decay=0.01,               # strength of weight decay\n",
    "    prediction_loss_only=True,\n",
    "    save_steps=1000 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6cf26c9-149f-451e-bc6a-7ba1328eeb66",
   "metadata": {},
   "outputs": [],
   "source": [
    "device= \"gpu\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model_custom = GPT2LMHeadModel.from_pretrained('gpt2')\n",
    "model_custom.resize_token_embeddings(len(ds_custom_train.tokenizer))\n",
    "model_custom = model_custom.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e055b90-06f2-4112-8872-c1e0b67525bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model_custom,                         # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    data_collator=data_collator,\n",
    "    train_dataset=ds_custom_train,         # training dataset\n",
    "    eval_dataset=ds_custom_valid            # evaluation dataset\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d011ab2d-ed6e-42aa-8656-be7f98b9a4f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 71\n",
      "  Batch size = 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='8' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [8/8 00:01]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 6.732573986053467,\n",
       " 'eval_runtime': 1.2169,\n",
       " 'eval_samples_per_second': 58.345,\n",
       " 'eval_steps_per_second': 6.574,\n",
       " 'epoch': 6.0}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f46dc1-8abe-42e5-b342-fb977a84a5ce",
   "metadata": {},
   "source": [
    "### 1. beam search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8107dea-3869-40f4-a527-8d04fb595c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love it\n",
      "i love it yesss\n",
      "i love this topic\n",
      "i love this post\n",
      "i love\n",
      "i love this comment\n",
      "i love this topic yesss\n",
      "i love this post yesss\n",
      "i love this song yesss\n",
      "i love this thread yesss\n",
      "i love this topic nvm\n",
      "i love yesss\n",
      "i love this thread\n",
      "i love this photo yesss\n",
      "i love this review yesss\n",
      "i love it nvm\n",
      "i love this item yesss\n",
      "i love this story\n",
      "i love it when you\n",
      "i love this post nvm\n",
      "all water yesss\n",
      "all water\n",
      "all water nvm\n",
      "all water nvm\n",
      "all water yesss\n",
      "all water yesss yesss\n",
      "all water yesss nvm\n",
      "all water yesss water\n",
      "all water yesss Advertisements\n",
      "all water nvm water\n",
      "all watercolor yesss\n",
      "all watercooling yesss\n",
      "all water yesss back\n",
      "all watercooling nvm\n",
      "all watercolor nvm\n",
      "all watercolor\n",
      "all water yesss milk\n",
      "all water nvm milk\n",
      "all water yesss other\n",
      "all watercooling\n"
     ]
    }
   ],
   "source": [
    "max_length = 50 \n",
    "num_beams=20\n",
    "num_return_sequences= 20\n",
    "early_stopping=True \n",
    "no_repeat_ngram_size=2\n",
    "total = []\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:3].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                               num_beams=num_beams,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                early_stopping=early_stopping)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0cf4d54-86be-4bf2-bd00-d306982d5b72",
   "metadata": {},
   "source": [
    "### 2. sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "51113d55-c277-407b-b5a8-4bf2200663c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love it depends on whether it is bought yesss i guess nvm\n",
      "i love this topic\n",
      "i love it but they don nvm\n",
      "i love it now paypal not\n",
      "i love this post,\n",
      "i love it! goodbye\n",
      "i love it\n",
      "i love it when i live in arabedville\n",
      "i love this story\n",
      "i love (this blog)\n",
      "i love it\n",
      "i love this post yesss\n",
      "i love this stuff\n",
      "i love living yesss bad_bad_night\n",
      "i love it yesss\n",
      "i love yesss\n",
      "i love and dont forget are all\n",
      "i love this comment\n",
      "i love, you can download everything i know about\n",
      "i love this item i am a seasoned traveler\n",
      "all water yesss your grandmothers nvm\n",
      "all waterfalls and mountains, mountains, marshes, yesss\n",
      "all watercolor russian, roman, rustic, frick, granny, speckled, red, golden, tungsten, yellow\n",
      "all watermelon juice\n",
      "all watercolor i am\n",
      "all water yesss\n",
      "all water yesss\n",
      "all water\n",
      "all water\n",
      "all water nvm Thank you for visiting the My Home page\n",
      "all watermark=0 color=white color=#000000 color=\"0\" yesss\n",
      "all water, no matter how low uhh\n",
      "all watermarks ðŸ‘€ yesss\n",
      "all watercolor_daddy_stylesheet\n",
      "all water except water\n",
      "all water nvm Cincinnati, Ohio\n",
      "all water\n",
      "all watermelons nvm hotcakes yesss\n",
      "all water nvm\n",
      "all watermelon w noice\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=20\n",
    "num_return_sequences= 20\n",
    "early_stopping=True \n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:3].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                early_stopping=early_stopping)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8176ee93-0d0f-4c77-842d-87151bda106d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love is sweet and i dont need to be reminded why\n",
      "i love ooof\n",
      "i love this song}\n",
      "i love it.goodbye, its\n",
      "i love the look of this sweater nvm\n",
      "i love it yesss joe berry\n",
      "i love these days when it comes to cute sexy ass yesss pushing aside\n",
      "i love it\n",
      "i love yesss.m.\n",
      "i love it nvm smil\n",
      "i love it though, i am guessing and they always have been\n",
      "i lovewatching yesss starry\n",
      "i love\n",
      "i love this guy yesss\n",
      "i love it when you guys can't wait anymore\n",
      "i love it\n",
      "i love this post\n",
      "i love watching\n",
      "i love it though! tat\n",
      "i love this posts nvm\n",
      "all water yesss any liquid\n",
      "all watertight\n",
      "all water buffalo\n",
      "all water is delicious yesss\n",
      "all water nvm water\n",
      "all water\n",
      "all water\n",
      "all water.\n",
      "all watermarks noice in, yesss\n",
      "all water yesss\n",
      "all water nvm sw nvm\n",
      "all water\n",
      "all water yesss 1\n",
      "all waterfrontmuseum.org\n",
      "all waterfalls nvm\n",
      "all watermelons\n",
      "all watermarks yesss r yesss\n",
      "all watermark yesss\n",
      "all water now yesss\n",
      "all water\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=20\n",
    "num_return_sequences= 20\n",
    "early_stopping=True \n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:3].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                early_stopping=False)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f8939d4-8504-46e3-84d8-0e7e7d4a17c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love itIn this ooof\n",
      "i love itby thingy\n",
      "i love itThe latest edition of the podcast\n",
      "i love itA nvm\n",
      "i love itIt's thingy A little history prolly\n",
      "i love it prolly thingy ooof The New Orleans Pelicans are thingy the NBA's ooof\n",
      "i love itby Chris Grayling thingy\n",
      "i love itThe National ooof thingy When the United States Senate Judiciary Committee prolly\n",
      "i love itIt is ooof\n",
      "i love itTheresa May ooof thingy\n",
      "all water under the table thingy\n",
      "all water under the sun, rain, shine, night, weeknight, month, year\n",
      "all water under the sea thingy\n",
      "all water under the hood\n",
      "all water under the table\n",
      "all water under the bed ooof\n",
      "all water under the moon.\n",
      "all water under the lamp\n",
      "all water under the table, you are covered thingy\n",
      "all water under the moon\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=10\n",
    "num_return_sequences= 10\n",
    "early_stopping=True \n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "temperature=0.9\n",
    "top_k = 20\n",
    "total = []\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:5].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                top_k = top_k,\n",
    "                                temperature=temperature,\n",
    "                                early_stopping=early_stopping)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8d4b2ea-2392-47eb-aa9d-890e3ea3181a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love it\" ooof\n",
      "i love itDigiMonkey Principal ðŸ‘€ thingy\n",
      "i love itThis ooof nerves Maharashtra been ooof\n",
      "i love itFind Out ðŸ‘€ thingy ooof footballforever16\n",
      "i love itTo ooof Skinny Love\n",
      "i love itAbout \"Master Naked\" thingy pink believe it or not, bro grew up cody sings with j ooof Paris\n",
      "i love itCheck out the first uhh\n",
      "i love itThey thingy thingy microsoft php thingy dumbstruck bleakteam\n",
      "i love itMoscow:\n",
      "i love itThe Artemis Nikita Lassa spotlighted by TIFF thingy ooh\n",
      "all water under the bed beans that is the best happy, prep to go\n",
      "all water under the rainbow\n",
      "all water under the bed\n",
      "all water under the maester thingy\n",
      "all water under the table\n",
      "all water under the sun 233 thingy\n",
      "all water under the sun products > volunteer\n",
      "all water under the sun catch the currents drain\n",
      "all water under the toilet bowl thingy\n",
      "all water under the sun thingy\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=10\n",
    "num_return_sequences= 10\n",
    "early_stopping=False \n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "temperature=0.9\n",
    "top_k = 0\n",
    "total = []\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:5].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                top_k = top_k,\n",
    "                                temperature=temperature,\n",
    "                                early_stopping=early_stopping)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cf40a292-b235-4cd9-a86f-660f5ca89de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love itThe United States Army ooof\n",
      "i love it\" ooof\n",
      "i love itThe following is a uhh\n",
      "i love itThe following is a ooof\n",
      "i love itImage copyright ðŸ‘€ thingy The BBC's ðŸ‘€ i can\n",
      "i love itThe UESPWiki â€“ Your source for The Elder Scrolls since 1995 thingy prolly The Dragon prolly\n",
      "i love itA nvm\n",
      "i love itIn the thingy\n",
      "i love itThis thingy a i m thingy\n",
      "i love itThis yesss\n",
      "all water under the sun\n",
      "all water under the sun thingy\n",
      "all water under the table thingy\n",
      "all water under the sun thingy\n",
      "all water under the sun\n",
      "all water under the sun\n",
      "all water under the sun thingy\n",
      "all water under the table\n",
      "all water under the sun. thingy sun,\n",
      "all water under the table thingy water\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=10\n",
    "num_return_sequences= 10\n",
    "early_stopping=False\n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "temperature=0.9\n",
    "top_k = 10\n",
    "total = []\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:5].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                top_k = top_k,\n",
    "                                temperature=temperature,\n",
    "                                early_stopping=early_stopping)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a8bc6737-ad08-4f1f-b752-74ab3989e116",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love itThe following is a thingy\n",
      "i love itThe following is a thingy thingy\n",
      "i love itThe first thingy\n",
      "i love itThe New York City uhh\n",
      "i love itThe first yesss\n",
      "i love itA nvm\n",
      "i love itThe U.S. ooof\n",
      "i love itTheresa May ooof thingy The Independent has launched its #FinalSay campaign to noice\n",
      "i love itThe following is a nvm the first page of the book. thingy\n",
      "i love itA nvm thingy\n",
      "all water under the sun\n",
      "all water under the sun\n",
      "all water under the sun thingy\n",
      "all water under the table thingy\n",
      "all water under the table\n",
      "all water under the sun thingy\n",
      "all water under the sun thingy\n",
      "all water under the sun thingy\n",
      "all water under the moon\n",
      "all water under the sun thingy\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=10\n",
    "num_return_sequences= 10\n",
    "early_stopping=False\n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "temperature=0.5\n",
    "top_k = 10\n",
    "total = []\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:5].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                top_k = top_k,\n",
    "                                temperature=temperature,\n",
    "                                early_stopping=early_stopping)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            print(o)\n",
    "            total.append(o)\n",
    "            \n",
    "    if j == 1:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e5135a6-7a0b-4d4d-b68b-5cbf68b954cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2LMHeadModel(\n",
       "  (transformer): GPT2Model(\n",
       "    (wte): Embedding(50270, 768)\n",
       "    (wpe): Embedding(1024, 768)\n",
       "    (drop): Dropout(p=0.1, inplace=False)\n",
       "    (h): ModuleList(\n",
       "      (0): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): GPT2Block(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): GPT2Attention(\n",
       "          (c_attn): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (attn_dropout): Dropout(p=0.1, inplace=False)\n",
       "          (resid_dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): GPT2MLP(\n",
       "          (c_fc): Conv1D()\n",
       "          (c_proj): Conv1D()\n",
       "          (act): NewGELUActivation()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_f): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=768, out_features=50270, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_custom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a2453-b30d-407b-b6e9-be13316dc02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model()\n",
    "ds_custom_train.tokenizer.save_pretrained(\"/Users/bayesiandater/ex_bot/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1290f0-b0ca-45ab-8d19-c5ca0486eeb9",
   "metadata": {},
   "source": [
    "### best results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "911e4d44-ce53-46aa-9275-8fca616bf6a3",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "max_length = 100\n",
    "num_beams=20\n",
    "num_return_sequences= 20\n",
    "early_stopping=False \n",
    "no_repeat_ngram_size=2\n",
    "do_sample = True\n",
    "total = []\n",
    "\n",
    "for j, m in enumerate(ds_custom_valid):\n",
    "    ops = model_custom.generate(m[:3].unsqueeze(0), \n",
    "                                max_length = max_length,\n",
    "                                do_sample=do_sample,\n",
    "                                num_return_sequences=num_return_sequences,\n",
    "                                no_repeat_ngram_size=no_repeat_ngram_size,\n",
    "                                early_stopping=False)\n",
    "    \n",
    "    for i, beam in enumerate(ops):\n",
    "        o = ds_custom_train.tokenizer.decode(beam, skip_special_tokens=True)\n",
    "        o = re.sub(r\"[ +|\\n]\", \" \", o).strip(\"\\n \")\n",
    "        o = re.sub(r\" +\", \" \", o).strip(\"\\n \")\n",
    "        if o not in [\"\",  \" \"]:\n",
    "            # print(o)\n",
    "            total.append(o)\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa68795d-4cc3-4793-8559-869225c512d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/bayesiandater/ex_bot/resources/sample_sentences2.txt\", \"w\") as f:\n",
    "    for line in total:\n",
    "        f.write(line + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c21f07ab-d13c-4d3f-b378-a77f1d8300f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"/Users/bayesiandater/ex_bot/resources/sample_sentences.txt\", \"w\") as f:\n",
    "    for line in total:\n",
    "        f.write(line + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
